# -*- coding: utf-8 -*-
"""Mini Project 6.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-vIiLlos-vkuDa7-ulUb7K7DdaCOxKsu
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.applications import DenseNet201
from tensorflow.keras.applications.vgg19 import preprocess_input
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
import numpy as np
import pandas as pd
import os
import cv2

train="/content/drive/MyDrive/knee/Osteoarthritis_Assignment_dataset/train"
test="/content/drive/MyDrive/knee/Osteoarthritis_Assignment_dataset/test"
val="/content/drive/MyDrive/knee/Osteoarthritis_Assignment_dataset/Valid"

x_train=[]
for folder in os.listdir(train):
    sub_path=train+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(80,80))
        x_train.append(img_arr)
x_test=[]
for folder in os.listdir(test):
    sub_path=test+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(80,80))
        x_test.append(img_arr)
x_val=[]
for folder in os.listdir(val):
    sub_path=val+"/"+folder
    for img in os.listdir(sub_path):
        image_path=sub_path+"/"+img
        img_arr=cv2.imread(image_path)
        img_arr=cv2.resize(img_arr,(80,80))
        x_val.append(img_arr)

train_x=np.array(x_train)
test_x=np.array(x_test)
val_x=np.array(x_val)

train_x=train_x/255.0
test_x=test_x/255.0
val_x=val_x/255.0

train_datagen = ImageDataGenerator(rescale = 1./255)
test_datagen = ImageDataGenerator(rescale = 1./255)
val_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory(train,
                                                target_size = (80, 80),
                                                batch_size = 16,
                                                class_mode = 'categorical')
test_set = test_datagen.flow_from_directory(test,
                                            target_size = (80, 80),
                                            batch_size = 16,
                                            class_mode = 'categorical')
val_set = val_datagen.flow_from_directory(val,
                                        target_size = (80, 80),
                                        batch_size = 16,
                                        class_mode = 'categorical')

train_y=training_set.classes
test_y=test_set.classes
val_y=val_set.classes

training_set.class_indices

train_y.shape,test_y.shape,val_y.shape

dense_net = DenseNet201(input_shape = (80, 80, 3), weights='imagenet', include_top=False)

for layer in dense_net.layers:
    layer.trainable = False

x = Flatten()(dense_net.output)

x = Dropout(0.5)(x)
prediction = Dense(2, activation='sigmoid')(x)

model = Model(inputs=dense_net.input, outputs=prediction)

model.summary()

model.compile(
 loss='sparse_categorical_crossentropy',
 optimizer="adam",
 metrics=['accuracy']
)

# from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger
# checkpoint = ModelCheckpoint('./Osteoarthritis_Assignment_dataset/DenseNet Model/weights-imporvement-{epoch:02d}-{val_accuracy:.2f}.hdf5',
#                             monitor = 'val_accuracy', save_best_only = True, verbose = 1)
# early_stop=EarlyStopping(monitor='val_loss',mode='min',verbose=1, patience=5)
# #Early stopping to avoid overfitting of model
# log_csv = CSVLogger('./Osteoarthritis_Assignment_dataset/DenseNet Model/my_log.csv', separator=',', append = False)

# fit the model
history = model.fit(
 train_x,
 train_y,
 validation_data=(val_x,val_y),
 epochs=50,
#  callbacks=[checkpoint, log_csv],
 batch_size=64,shuffle=True)

import matplotlib.pyplot as plt

# accuracies
plt.plot(history.history['accuracy'], label='train accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.legend()
plt.show()

# loss
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.legend()
plt.savefig('dense_net-loss-rps-1.png')
plt.show()

"""## Model Accuracy"""

print("[Loss, Accuracy] = ", model.evaluate(test_x,test_y,batch_size=64))

# image_test_path="/content/drive/MyDrive/knee/Osteoarthritis_Assignment_dataset/test/Osteoarthritis"
image_test_lst=[]
# for img in os.listdir(image_test_path):
#     image_path=image_test_path+"/"+img
#     img_arr=cv2.imread(image_path)
#     img_arr=cv2.resize(img_arr,(80,80))
#     image_test_lst.append(np.array(img_arr))
image_test_path="/content/drive/MyDrive/knee/Osteoarthritis_Assignment_dataset/test/Osteoarthritis/9093622_1.png"
img_arr=cv2.imread(image_test_path)
img_arr=cv2.resize(img_arr,(80,80))
image_test_lst.append(np.array(img_arr))
x = np.asarray(image_test_lst)
x = x/255.0

y_ped=model.predict(x)

y_ped

y_pred=np.argmax(y_ped,axis=1)

y_pred

plt.imshow(img_arr)

c=0
for i in range(len(y_pred)):
  if(y_pred[i]==0):
    c+=1
c

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
import numpy as np

test_x

#predict
y_pred=model.predict(test_x)
y_pred=np.argmax(y_pred,axis=1)

#get classification report
print(classification_report(y_pred,test_y))

#get confusion matrix
print(confusion_matrix(y_pred,test_y))